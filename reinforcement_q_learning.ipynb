{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheo/.local/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "\n",
    "env = gym.make('CartPole-v0').unwrapped\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# if gpu is to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replay Memory\n",
    "-------------\n",
    "\n",
    "We'll be using experience replay memory for training our DQN. It stores\n",
    "the transitions that the agent observes, allowing us to reuse this data\n",
    "later. By sampling from it randomly, the transitions that build up a\n",
    "batch are decorrelated. It has been shown that this greatly stabilizes\n",
    "and improves the DQN training procedure.\n",
    "\n",
    "For this, we're going to need two classses:\n",
    "\n",
    "-  ``Transition`` - a named tuple representing a single transition in\n",
    "   our environment. It essentially maps (state, action) pairs\n",
    "   to their (next_state, reward) result, with the state being the\n",
    "   screen difference image as described later on.\n",
    "-  ``ReplayMemory`` - a cyclic buffer of bounded size that holds the\n",
    "   transitions observed recently. It also implements a ``.sample()``\n",
    "   method for selecting a random batch of transitions for training.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's define our model. But first, let quickly recap what a DQN is.\n",
    "\n",
    "DQN algorithm\n",
    "-------------\n",
    "\n",
    "Our environment is deterministic, so all equations presented here are\n",
    "also formulated deterministically for the sake of simplicity. In the\n",
    "reinforcement learning literature, they would also contain expectations\n",
    "over stochastic transitions in the environment.\n",
    "\n",
    "Our aim will be to train a policy that tries to maximize the discounted,\n",
    "cumulative reward\n",
    "$R_{t_0} = \\sum_{t=t_0}^{\\infty} \\gamma^{t - t_0} r_t$, where\n",
    "$R_{t_0}$ is also known as the *return*. The discount,\n",
    "$\\gamma$, should be a constant between $0$ and $1$\n",
    "that ensures the sum converges. It makes rewards from the uncertain far\n",
    "future less important for our agent than the ones in the near future\n",
    "that it can be fairly confident about.\n",
    "\n",
    "The main idea behind Q-learning is that if we had a function\n",
    "$Q^*: State \\times Action \\rightarrow \\mathbb{R}$, that could tell\n",
    "us what our return would be, if we were to take an action in a given\n",
    "state, then we could easily construct a policy that maximizes our\n",
    "rewards:\n",
    "\n",
    "\\begin{align}\\pi^*(s) = \\arg\\!\\max_a \\ Q^*(s, a)\\end{align}\n",
    "\n",
    "However, we don't know everything about the world, so we don't have\n",
    "access to $Q^*$. But, since neural networks are universal function\n",
    "approximators, we can simply create one and train it to resemble\n",
    "$Q^*$.\n",
    "\n",
    "For our training update rule, we'll use a fact that every $Q$\n",
    "function for some policy obeys the Bellman equation:\n",
    "\n",
    "\\begin{align}Q^{\\pi}(s, a) = r + \\gamma Q^{\\pi}(s', \\pi(s'))\\end{align}\n",
    "\n",
    "The difference between the two sides of the equality is known as the\n",
    "temporal difference error, $\\delta$:\n",
    "\n",
    "\\begin{align}\\delta = Q(s, a) - (r + \\gamma \\max_a Q(s', a))\\end{align}\n",
    "\n",
    "To minimise this error, we will use the `Huber\n",
    "loss <https://en.wikipedia.org/wiki/Huber_loss>`__. The Huber loss acts\n",
    "like the mean squared error when the error is small, but like the mean\n",
    "absolute error when the error is large - this makes it more robust to\n",
    "outliers when the estimates of $Q$ are very noisy. We calculate\n",
    "this over a batch of transitions, $B$, sampled from the replay\n",
    "memory:\n",
    "\n",
    "\\begin{align}\\mathcal{L} = \\frac{1}{|B|}\\sum_{(s, a, s', r) \\ \\in \\ B} \\mathcal{L}(\\delta)\\end{align}\n",
    "\n",
    "\\begin{align}\\text{where} \\quad \\mathcal{L}(\\delta) = \\begin{cases}\n",
    "     \\frac{1}{2}{\\delta^2}  & \\text{for } |\\delta| \\le 1, \\\\\n",
    "     |\\delta| - \\frac{1}{2} & \\text{otherwise.}\n",
    "   \\end{cases}\\end{align}\n",
    "\n",
    "Q-network\n",
    "^^^^^^^^^\n",
    "\n",
    "Our model will be a convolutional neural network that takes in the\n",
    "difference between the current and previous screen patches. It has two\n",
    "outputs, representing $Q(s, \\mathrm{left})$ and\n",
    "$Q(s, \\mathrm{right})$ (where $s$ is the input to the\n",
    "network). In effect, the network is trying to predict the *expected return* of\n",
    "taking each action given the current input.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, h, w, outputs):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "\n",
    "        # Number of Linear input connections depends on output of conv2d layers\n",
    "        # and therefore the input image size, so compute it.\n",
    "        def conv2d_size_out(size, kernel_size = 5, stride = 2):\n",
    "            return (size - (kernel_size - 1) - 1) // stride  + 1\n",
    "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n",
    "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n",
    "        linear_input_size = convw * convh * 32\n",
    "        self.head = nn.Linear(linear_input_size, outputs)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        return self.head(x.view(x.size(0), -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Reinforcement Learning (DQN) Tutorial\n",
    "=====================================\n",
    "**Author**: `Adam Paszke <https://github.com/apaszke>`_\n",
    "\n",
    "\n",
    "This tutorial shows how to use PyTorch to train a Deep Q Learning (DQN) agent\n",
    "on the CartPole-v0 task from the `OpenAI Gym <https://gym.openai.com/>`__.\n",
    "\n",
    "**Task**\n",
    "\n",
    "The agent has to decide between two actions - moving the cart left or\n",
    "right - so that the pole attached to it stays upright. You can find an\n",
    "official leaderboard with various algorithms and visualizations at the\n",
    "`Gym website <https://gym.openai.com/envs/CartPole-v0>`__.\n",
    "\n",
    ".. figure:: /_static/img/cartpole.gif\n",
    "   :alt: cartpole\n",
    "\n",
    "   cartpole\n",
    "\n",
    "As the agent observes the current state of the environment and chooses\n",
    "an action, the environment *transitions* to a new state, and also\n",
    "returns a reward that indicates the consequences of the action. In this\n",
    "task, rewards are +1 for every incremental timestep and the environment\n",
    "terminates if the pole falls over too far or the cart moves more then 2.4\n",
    "units away from center. This means better performing scenarios will run\n",
    "for longer duration, accumulating larger return.\n",
    "\n",
    "The CartPole task is designed so that the inputs to the agent are 4 real\n",
    "values representing the environment state (position, velocity, etc.).\n",
    "However, neural networks can solve the task purely by looking at the\n",
    "scene, so we'll use a patch of the screen centered on the cart as an\n",
    "input. Because of this, our results aren't directly comparable to the\n",
    "ones from the official leaderboard - our task is much harder.\n",
    "Unfortunately this does slow down the training, because we have to\n",
    "render all the frames.\n",
    "\n",
    "Strictly speaking, we will present the state as the difference between\n",
    "the current screen patch and the previous one. This will allow the agent\n",
    "to take the velocity of the pole into account from one image.\n",
    "\n",
    "**Packages**\n",
    "\n",
    "\n",
    "First, let's import needed packages. Firstly, we need\n",
    "`gym <https://gym.openai.com/docs>`__ for the environment\n",
    "(Install using `pip install gym`).\n",
    "We'll also use the following from PyTorch:\n",
    "\n",
    "-  neural networks (``torch.nn``)\n",
    "-  optimization (``torch.optim``)\n",
    "-  automatic differentiation (``torch.autograd``)\n",
    "-  utilities for vision tasks (``torchvision`` - `a separate\n",
    "   package <https://github.com/pytorch/vision>`__).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input extraction\n",
    "^^^^^^^^^^^^^^^^\n",
    "\n",
    "The code below are utilities for extracting and processing rendered\n",
    "images from the environment. It uses the ``torchvision`` package, which\n",
    "makes it easy to compose image transforms. Once you run the cell it will\n",
    "display an example patch that it extracted.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "resize = T.Compose([T.ToPILImage(),\n",
    "                    T.Resize(40, interpolation=Image.CUBIC),\n",
    "                    T.ToTensor()])\n",
    "\n",
    "\n",
    "def get_cart_location(screen_width):\n",
    "    world_width = env.x_threshold * 2\n",
    "    scale = screen_width / world_width\n",
    "    return int(env.state[0] * scale + screen_width / 2.0)  # MIDDLE OF CART\n",
    "\n",
    "def get_screen():\n",
    "    # Returned screen requested by gym is 400x600x3, but is sometimes larger\n",
    "    # such as 800x1200x3. Transpose it into torch order (CHW).\n",
    "    screen = env.render(mode='rgb_array').transpose((2, 0, 1))\n",
    "    # Cart is in the lower half, so strip off the top and bottom of the screen\n",
    "    _, screen_height, screen_width = screen.shape\n",
    "    screen = screen[:, int(screen_height*0.4):int(screen_height * 0.8)]\n",
    "    view_width = int(screen_width * 0.6)\n",
    "    cart_location = get_cart_location(screen_width)\n",
    "    if cart_location < view_width // 2:\n",
    "        slice_range = slice(view_width)\n",
    "    elif cart_location > (screen_width - view_width // 2):\n",
    "        slice_range = slice(-view_width, None)\n",
    "    else:\n",
    "        slice_range = slice(cart_location - view_width // 2,\n",
    "                            cart_location + view_width // 2)\n",
    "    # Strip off the edges, so that we have a square image centered on a cart\n",
    "    screen = screen[:, :, slice_range]\n",
    "    # Convert to float, rescale, convert to torch tensor\n",
    "    # (this doesn't require a copy)\n",
    "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "    screen = torch.from_numpy(screen)\n",
    "    # Resize, and add a batch dimension (BCHW)\n",
    "    return resize(screen).unsqueeze(0).to(device)\n",
    "\n",
    "\n",
    "env.reset()\n",
    "plt.figure()\n",
    "plt.imshow(get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(),\n",
    "           interpolation='none')\n",
    "plt.title('Example extracted screen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training\n",
    "--------\n",
    "\n",
    "Hyperparameters and utilities\n",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "This cell instantiates our model and its optimizer, and defines some\n",
    "utilities:\n",
    "\n",
    "-  ``select_action`` - will select an action accordingly to an epsilon\n",
    "   greedy policy. Simply put, we'll sometimes use our model for choosing\n",
    "   the action, and sometimes we'll just sample one uniformly. The\n",
    "   probability of choosing a random action will start at ``EPS_START``\n",
    "   and will decay exponentially towards ``EPS_END``. ``EPS_DECAY``\n",
    "   controls the rate of the decay.\n",
    "-  ``plot_durations`` - a helper for plotting the durations of episodes,\n",
    "   along with an average over the last 100 episodes (the measure used in\n",
    "   the official evaluations). The plot will be underneath the cell\n",
    "   containing the main training loop, and will update after every\n",
    "   episode.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.999\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "TARGET_UPDATE = 10\n",
    "\n",
    "# Get screen size so that we can initialize layers correctly based on shape\n",
    "# returned from AI gym. Typical dimensions at this point are close to 3x40x90\n",
    "# which is the result of a clamped and down-scaled render buffer in get_screen()\n",
    "init_screen = get_screen()\n",
    "_, _, screen_height, screen_width = init_screen.shape\n",
    "\n",
    "# Get number of actions from gym action space\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "policy_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "target_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "optimizer = optim.RMSprop(policy_net.parameters())\n",
    "memory = ReplayMemory(10000)\n",
    "\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            return policy_net(state).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long)\n",
    "\n",
    "\n",
    "episode_durations = []\n",
    "\n",
    "\n",
    "def plot_durations():\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    if is_ipython:\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training loop\n",
    "^^^^^^^^^^^^^\n",
    "\n",
    "Finally, the code for training our model.\n",
    "\n",
    "Here, you can find an ``optimize_model`` function that performs a\n",
    "single step of the optimization. It first samples a batch, concatenates\n",
    "all the tensors into a single one, computes $Q(s_t, a_t)$ and\n",
    "$V(s_{t+1}) = \\max_a Q(s_{t+1}, a)$, and combines them into our\n",
    "loss. By defition we set $V(s) = 0$ if $s$ is a terminal\n",
    "state. We also use a target network to compute $V(s_{t+1})$ for\n",
    "added stability. The target network has its weights kept frozen most of\n",
    "the time, but is updated with the policy network's weights every so often.\n",
    "This is usually a set number of steps but we shall use episodes for\n",
    "simplicity.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation). This converts batch-array of Transitions\n",
    "    # to Transition of batch-arrays.\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    # (a final state would've been the one after which simulation ended)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    \n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # Expected values of actions for non_final_next_states are computed based\n",
    "    # on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Compute Huber loss\n",
    "    print(\"============================\")\n",
    "    print(state_action_values.size())\n",
    "    print(expected_state_action_values.unsqueeze(1).size())\n",
    "    print(state_action_values)\n",
    "    print(expected_state_action_values.unsqueeze(1))\n",
    "    print(\"============================\")\n",
    "    \n",
    "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, you can find the main training loop. At the beginning we reset\n",
    "the environment and initialize the ``state`` Tensor. Then, we sample\n",
    "an action, execute it, observe the next screen and the reward (always\n",
    "1), and optimize our model once. When the episode ends (our model\n",
    "fails), we restart the loop.\n",
    "\n",
    "Below, `num_episodes` is set small. You should download\n",
    "the notebook and run lot more epsiodes, such as 300+ for meaningful\n",
    "duration improvements.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "torch.Size([128, 1])\n",
      "torch.Size([128, 1])\n",
      "tensor([[2.4422],\n",
      "        [2.4968],\n",
      "        [1.3991],\n",
      "        [2.4620],\n",
      "        [2.4585],\n",
      "        [2.1656],\n",
      "        [2.3903],\n",
      "        [2.4431],\n",
      "        [2.6102],\n",
      "        [2.5074],\n",
      "        [2.5010],\n",
      "        [2.3742],\n",
      "        [2.4720],\n",
      "        [2.4937],\n",
      "        [1.6176],\n",
      "        [2.4212],\n",
      "        [1.6573],\n",
      "        [2.3393],\n",
      "        [2.6507],\n",
      "        [2.5577],\n",
      "        [2.5925],\n",
      "        [2.5641],\n",
      "        [2.4463],\n",
      "        [2.5537],\n",
      "        [2.5217],\n",
      "        [2.4243],\n",
      "        [2.5715],\n",
      "        [2.4853],\n",
      "        [2.5195],\n",
      "        [2.4042],\n",
      "        [2.4716],\n",
      "        [1.9283],\n",
      "        [2.5010],\n",
      "        [2.5805],\n",
      "        [2.5290],\n",
      "        [2.5010],\n",
      "        [2.4909],\n",
      "        [2.2556],\n",
      "        [2.2888],\n",
      "        [2.4470],\n",
      "        [2.1970],\n",
      "        [2.4305],\n",
      "        [2.4965],\n",
      "        [2.5408],\n",
      "        [2.4207],\n",
      "        [2.5288],\n",
      "        [2.2415],\n",
      "        [2.6163],\n",
      "        [2.6193],\n",
      "        [2.5439],\n",
      "        [2.1501],\n",
      "        [2.5603],\n",
      "        [2.4585],\n",
      "        [2.0184],\n",
      "        [2.3301],\n",
      "        [2.6284],\n",
      "        [2.5662],\n",
      "        [2.1170],\n",
      "        [2.3743],\n",
      "        [2.5010],\n",
      "        [2.4726],\n",
      "        [2.3436],\n",
      "        [1.8306],\n",
      "        [2.4715],\n",
      "        [1.9569],\n",
      "        [2.5165],\n",
      "        [2.5178],\n",
      "        [2.4172],\n",
      "        [2.3822],\n",
      "        [2.4720],\n",
      "        [2.4369],\n",
      "        [2.5246],\n",
      "        [2.5632],\n",
      "        [2.4802],\n",
      "        [2.1740],\n",
      "        [2.2795],\n",
      "        [2.5010],\n",
      "        [2.4248],\n",
      "        [2.5060],\n",
      "        [2.4277],\n",
      "        [2.4100],\n",
      "        [2.6255],\n",
      "        [2.3671],\n",
      "        [1.8006],\n",
      "        [2.0743],\n",
      "        [2.5520],\n",
      "        [2.5383],\n",
      "        [2.5006],\n",
      "        [2.5886],\n",
      "        [2.5010],\n",
      "        [2.5382],\n",
      "        [2.5923],\n",
      "        [2.4554],\n",
      "        [2.4057],\n",
      "        [2.5521],\n",
      "        [2.4870],\n",
      "        [2.5056],\n",
      "        [2.5412],\n",
      "        [2.4721],\n",
      "        [2.5174],\n",
      "        [2.5125],\n",
      "        [2.5023],\n",
      "        [2.5532],\n",
      "        [2.5379],\n",
      "        [2.1796],\n",
      "        [1.8770],\n",
      "        [2.3084],\n",
      "        [2.1774],\n",
      "        [2.5760],\n",
      "        [2.4632],\n",
      "        [2.4170],\n",
      "        [2.4322],\n",
      "        [2.3841],\n",
      "        [2.4724],\n",
      "        [2.4939],\n",
      "        [2.5005],\n",
      "        [2.6263],\n",
      "        [2.5018],\n",
      "        [1.3605],\n",
      "        [2.4711],\n",
      "        [2.4516],\n",
      "        [2.5010],\n",
      "        [2.5010],\n",
      "        [2.5059],\n",
      "        [2.4131],\n",
      "        [2.5090],\n",
      "        [2.4463],\n",
      "        [2.4907]], grad_fn=<GatherBackward>)\n",
      "tensor([[2.2382],\n",
      "        [2.3600],\n",
      "        [1.0000],\n",
      "        [2.1511],\n",
      "        [2.2710],\n",
      "        [2.2950],\n",
      "        [2.0859],\n",
      "        [2.2066],\n",
      "        [2.2834],\n",
      "        [2.2977],\n",
      "        [2.2916],\n",
      "        [2.0387],\n",
      "        [2.2175],\n",
      "        [2.2805],\n",
      "        [1.0000],\n",
      "        [2.2286],\n",
      "        [1.0000],\n",
      "        [1.8954],\n",
      "        [2.2663],\n",
      "        [2.3193],\n",
      "        [2.2772],\n",
      "        [2.2685],\n",
      "        [2.2353],\n",
      "        [2.2472],\n",
      "        [2.3463],\n",
      "        [2.2768],\n",
      "        [2.3767],\n",
      "        [2.1301],\n",
      "        [2.2237],\n",
      "        [2.1019],\n",
      "        [2.2359],\n",
      "        [1.9912],\n",
      "        [2.2640],\n",
      "        [2.2620],\n",
      "        [2.3221],\n",
      "        [2.2910],\n",
      "        [2.0921],\n",
      "        [2.0336],\n",
      "        [1.9803],\n",
      "        [2.1982],\n",
      "        [1.9768],\n",
      "        [2.2617],\n",
      "        [2.3635],\n",
      "        [2.2624],\n",
      "        [2.0265],\n",
      "        [2.2495],\n",
      "        [1.9497],\n",
      "        [2.2941],\n",
      "        [2.3425],\n",
      "        [2.2891],\n",
      "        [1.9682],\n",
      "        [2.2395],\n",
      "        [2.1493],\n",
      "        [1.0000],\n",
      "        [1.9607],\n",
      "        [2.2885],\n",
      "        [2.0705],\n",
      "        [1.0000],\n",
      "        [2.1516],\n",
      "        [2.2937],\n",
      "        [2.3272],\n",
      "        [1.7655],\n",
      "        [2.1175],\n",
      "        [2.2105],\n",
      "        [1.9891],\n",
      "        [2.2110],\n",
      "        [2.2386],\n",
      "        [2.2409],\n",
      "        [2.0794],\n",
      "        [2.2476],\n",
      "        [2.2606],\n",
      "        [2.2938],\n",
      "        [2.2909],\n",
      "        [2.0490],\n",
      "        [1.8558],\n",
      "        [1.9866],\n",
      "        [2.2913],\n",
      "        [2.0888],\n",
      "        [2.3274],\n",
      "        [2.1072],\n",
      "        [2.2627],\n",
      "        [2.2513],\n",
      "        [2.0953],\n",
      "        [1.0000],\n",
      "        [1.8263],\n",
      "        [2.2686],\n",
      "        [2.0960],\n",
      "        [2.0743],\n",
      "        [2.3085],\n",
      "        [2.2944],\n",
      "        [2.3622],\n",
      "        [2.2817],\n",
      "        [2.2054],\n",
      "        [1.9801],\n",
      "        [2.2737],\n",
      "        [2.2910],\n",
      "        [2.2110],\n",
      "        [2.2892],\n",
      "        [2.1856],\n",
      "        [2.2994],\n",
      "        [2.3827],\n",
      "        [2.1334],\n",
      "        [2.2449],\n",
      "        [2.2604],\n",
      "        [1.8856],\n",
      "        [1.0000],\n",
      "        [2.2993],\n",
      "        [1.9894],\n",
      "        [2.3017],\n",
      "        [2.0402],\n",
      "        [2.1159],\n",
      "        [2.2083],\n",
      "        [2.1936],\n",
      "        [1.9078],\n",
      "        [2.2394],\n",
      "        [2.2620],\n",
      "        [2.2802],\n",
      "        [2.2348],\n",
      "        [1.0000],\n",
      "        [2.1957],\n",
      "        [2.2946],\n",
      "        [2.2945],\n",
      "        [2.2399],\n",
      "        [2.2933],\n",
      "        [2.2398],\n",
      "        [2.2899],\n",
      "        [2.2030],\n",
      "        [2.3215]])\n",
      "============================\n",
      "============================\n",
      "torch.Size([128, 1])\n",
      "torch.Size([128, 1])\n",
      "tensor([[1.9155],\n",
      "        [1.8754],\n",
      "        [1.8528],\n",
      "        [1.6628],\n",
      "        [1.7319],\n",
      "        [1.4436],\n",
      "        [1.8926],\n",
      "        [1.9375],\n",
      "        [1.9019],\n",
      "        [1.9288],\n",
      "        [1.7816],\n",
      "        [1.8918],\n",
      "        [1.8148],\n",
      "        [1.8876],\n",
      "        [1.7334],\n",
      "        [1.8546],\n",
      "        [1.3378],\n",
      "        [1.9160],\n",
      "        [1.7959],\n",
      "        [1.8989],\n",
      "        [1.7758],\n",
      "        [0.8708],\n",
      "        [1.7060],\n",
      "        [1.8562],\n",
      "        [1.7829],\n",
      "        [1.3946],\n",
      "        [1.8975],\n",
      "        [1.9153],\n",
      "        [1.8963],\n",
      "        [0.7096],\n",
      "        [0.5644],\n",
      "        [1.8593],\n",
      "        [1.8112],\n",
      "        [1.9231],\n",
      "        [1.9025],\n",
      "        [1.8378],\n",
      "        [1.8828],\n",
      "        [1.9594],\n",
      "        [1.8908],\n",
      "        [1.8788],\n",
      "        [1.4034],\n",
      "        [1.8074],\n",
      "        [1.8941],\n",
      "        [1.6971],\n",
      "        [1.8923],\n",
      "        [1.9325],\n",
      "        [1.7053],\n",
      "        [1.8926],\n",
      "        [1.8620],\n",
      "        [1.8036],\n",
      "        [1.8392],\n",
      "        [1.6707],\n",
      "        [1.0419],\n",
      "        [1.8520],\n",
      "        [1.9206],\n",
      "        [1.8976],\n",
      "        [1.6211],\n",
      "        [1.8693],\n",
      "        [1.4814],\n",
      "        [1.9443],\n",
      "        [1.7515],\n",
      "        [1.9341],\n",
      "        [1.8457],\n",
      "        [1.8870],\n",
      "        [1.8032],\n",
      "        [1.0369],\n",
      "        [1.6677],\n",
      "        [1.8703],\n",
      "        [1.7913],\n",
      "        [1.9427],\n",
      "        [1.7550],\n",
      "        [1.8926],\n",
      "        [1.7312],\n",
      "        [1.6489],\n",
      "        [1.6189],\n",
      "        [1.3452],\n",
      "        [1.9007],\n",
      "        [1.4244],\n",
      "        [1.8505],\n",
      "        [1.4711],\n",
      "        [1.7568],\n",
      "        [1.9052],\n",
      "        [1.8808],\n",
      "        [1.3670],\n",
      "        [1.8313],\n",
      "        [1.9122],\n",
      "        [1.8270],\n",
      "        [1.8311],\n",
      "        [0.9284],\n",
      "        [0.8317],\n",
      "        [1.7769],\n",
      "        [1.4359],\n",
      "        [1.8926],\n",
      "        [1.8926],\n",
      "        [1.4111],\n",
      "        [1.4446],\n",
      "        [1.8346],\n",
      "        [1.8649],\n",
      "        [1.9010],\n",
      "        [1.8754],\n",
      "        [1.9026],\n",
      "        [1.8803],\n",
      "        [1.8869],\n",
      "        [1.6328],\n",
      "        [1.8887],\n",
      "        [1.8324],\n",
      "        [1.9168],\n",
      "        [1.8468],\n",
      "        [1.9314],\n",
      "        [1.9552],\n",
      "        [1.8808],\n",
      "        [1.8422],\n",
      "        [1.8937],\n",
      "        [1.8855],\n",
      "        [1.8728],\n",
      "        [0.9094],\n",
      "        [1.9572],\n",
      "        [1.8980],\n",
      "        [1.7259],\n",
      "        [1.4304],\n",
      "        [1.8830],\n",
      "        [1.7217],\n",
      "        [1.7694],\n",
      "        [1.9366],\n",
      "        [1.7718],\n",
      "        [1.6062],\n",
      "        [1.9726],\n",
      "        [1.7876]], grad_fn=<GatherBackward>)\n",
      "tensor([[2.2869],\n",
      "        [2.3221],\n",
      "        [2.2617],\n",
      "        [1.9497],\n",
      "        [2.0356],\n",
      "        [2.0126],\n",
      "        [2.2569],\n",
      "        [2.3193],\n",
      "        [2.2817],\n",
      "        [2.3479],\n",
      "        [2.1765],\n",
      "        [2.3312],\n",
      "        [2.0888],\n",
      "        [2.2805],\n",
      "        [1.9801],\n",
      "        [2.2129],\n",
      "        [2.0961],\n",
      "        [2.1789],\n",
      "        [2.2993],\n",
      "        [2.2948],\n",
      "        [2.0285],\n",
      "        [1.0000],\n",
      "        [1.9358],\n",
      "        [2.1490],\n",
      "        [1.9907],\n",
      "        [1.0000],\n",
      "        [2.2395],\n",
      "        [2.2933],\n",
      "        [2.0705],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [2.2105],\n",
      "        [2.2751],\n",
      "        [2.2476],\n",
      "        [2.2891],\n",
      "        [2.1493],\n",
      "        [2.2624],\n",
      "        [2.2737],\n",
      "        [2.2620],\n",
      "        [2.1957],\n",
      "        [1.9791],\n",
      "        [2.2427],\n",
      "        [2.1192],\n",
      "        [2.0953],\n",
      "        [2.2686],\n",
      "        [2.2938],\n",
      "        [1.9866],\n",
      "        [2.2723],\n",
      "        [2.1936],\n",
      "        [2.2741],\n",
      "        [2.3104],\n",
      "        [1.9576],\n",
      "        [1.0000],\n",
      "        [2.1929],\n",
      "        [2.2834],\n",
      "        [2.3352],\n",
      "        [1.9678],\n",
      "        [2.2409],\n",
      "        [1.9678],\n",
      "        [2.2513],\n",
      "        [1.8882],\n",
      "        [2.3987],\n",
      "        [2.0617],\n",
      "        [2.2472],\n",
      "        [2.0745],\n",
      "        [1.0000],\n",
      "        [2.0336],\n",
      "        [2.3600],\n",
      "        [2.1159],\n",
      "        [2.2663],\n",
      "        [2.0265],\n",
      "        [2.2945],\n",
      "        [2.2341],\n",
      "        [2.0199],\n",
      "        [1.9476],\n",
      "        [2.1175],\n",
      "        [2.2331],\n",
      "        [2.0278],\n",
      "        [2.2012],\n",
      "        [1.9689],\n",
      "        [2.2359],\n",
      "        [2.2381],\n",
      "        [2.2696],\n",
      "        [2.2950],\n",
      "        [2.2382],\n",
      "        [2.2747],\n",
      "        [2.2516],\n",
      "        [2.2229],\n",
      "        [2.0230],\n",
      "        [1.0000],\n",
      "        [2.2348],\n",
      "        [1.9642],\n",
      "        [2.2944],\n",
      "        [2.2910],\n",
      "        [2.0533],\n",
      "        [2.1197],\n",
      "        [2.2532],\n",
      "        [2.2286],\n",
      "        [2.2909],\n",
      "        [2.4813],\n",
      "        [2.4140],\n",
      "        [2.2576],\n",
      "        [2.2351],\n",
      "        [1.9452],\n",
      "        [2.3635],\n",
      "        [2.2361],\n",
      "        [2.3463],\n",
      "        [2.2398],\n",
      "        [2.2444],\n",
      "        [2.2621],\n",
      "        [2.2977],\n",
      "        [2.0490],\n",
      "        [2.2570],\n",
      "        [2.2495],\n",
      "        [2.1636],\n",
      "        [2.0048],\n",
      "        [2.3140],\n",
      "        [2.3827],\n",
      "        [2.1019],\n",
      "        [1.9078],\n",
      "        [2.3272],\n",
      "        [1.7655],\n",
      "        [2.2175],\n",
      "        [2.1567],\n",
      "        [2.0859],\n",
      "        [2.1072],\n",
      "        [2.3017],\n",
      "        [2.2910]])\n",
      "============================\n",
      "============================\n",
      "torch.Size([128, 1])\n",
      "torch.Size([128, 1])\n",
      "tensor([[2.5392],\n",
      "        [2.5812],\n",
      "        [2.5602],\n",
      "        [2.5926],\n",
      "        [2.5926],\n",
      "        [2.2622],\n",
      "        [2.4902],\n",
      "        [2.4535],\n",
      "        [1.9499],\n",
      "        [2.5048],\n",
      "        [2.1058],\n",
      "        [2.4843],\n",
      "        [2.5248],\n",
      "        [2.5533],\n",
      "        [2.5609],\n",
      "        [2.4931],\n",
      "        [2.5487],\n",
      "        [2.5746],\n",
      "        [2.6401],\n",
      "        [2.5654],\n",
      "        [2.4679],\n",
      "        [2.4506],\n",
      "        [2.4641],\n",
      "        [2.5914],\n",
      "        [2.6133],\n",
      "        [2.5158],\n",
      "        [2.5584],\n",
      "        [2.1306],\n",
      "        [2.5546],\n",
      "        [2.6317],\n",
      "        [2.5139],\n",
      "        [2.5803],\n",
      "        [2.5940],\n",
      "        [2.3420],\n",
      "        [2.6433],\n",
      "        [2.6171],\n",
      "        [2.4562],\n",
      "        [2.6038],\n",
      "        [2.5743],\n",
      "        [2.4606],\n",
      "        [2.3107],\n",
      "        [2.4692],\n",
      "        [2.5381],\n",
      "        [2.1003],\n",
      "        [2.4175],\n",
      "        [1.8425],\n",
      "        [2.5967],\n",
      "        [2.4519],\n",
      "        [2.5516],\n",
      "        [2.5352],\n",
      "        [2.5437],\n",
      "        [2.6117],\n",
      "        [2.0718],\n",
      "        [2.5696],\n",
      "        [2.5270],\n",
      "        [2.6901],\n",
      "        [2.5936],\n",
      "        [2.5243],\n",
      "        [2.6391],\n",
      "        [2.5959],\n",
      "        [2.6015],\n",
      "        [2.2781],\n",
      "        [2.5077],\n",
      "        [2.5958],\n",
      "        [1.7837],\n",
      "        [2.1915],\n",
      "        [2.5558],\n",
      "        [1.7681],\n",
      "        [2.4089],\n",
      "        [2.5926],\n",
      "        [2.5869],\n",
      "        [2.6088],\n",
      "        [2.5926],\n",
      "        [2.5965],\n",
      "        [2.3207],\n",
      "        [2.6379],\n",
      "        [2.5551],\n",
      "        [2.3014],\n",
      "        [2.4851],\n",
      "        [2.3215],\n",
      "        [2.5768],\n",
      "        [2.5413],\n",
      "        [2.4719],\n",
      "        [2.4722],\n",
      "        [2.4166],\n",
      "        [2.5926],\n",
      "        [2.4960],\n",
      "        [2.5926],\n",
      "        [2.5081],\n",
      "        [2.6012],\n",
      "        [2.5889],\n",
      "        [2.4999],\n",
      "        [2.3218],\n",
      "        [2.5926],\n",
      "        [2.3811],\n",
      "        [2.5440],\n",
      "        [2.4260],\n",
      "        [2.5570],\n",
      "        [2.5004],\n",
      "        [2.5521],\n",
      "        [2.4903],\n",
      "        [1.8617],\n",
      "        [2.4836],\n",
      "        [2.6794],\n",
      "        [2.5857],\n",
      "        [2.4329],\n",
      "        [2.4593],\n",
      "        [2.3049],\n",
      "        [2.4940],\n",
      "        [2.6145],\n",
      "        [2.4557],\n",
      "        [2.5835],\n",
      "        [2.3556],\n",
      "        [1.6621],\n",
      "        [2.5928],\n",
      "        [2.4811],\n",
      "        [2.3550],\n",
      "        [2.4725],\n",
      "        [2.6282],\n",
      "        [1.8037],\n",
      "        [2.6339],\n",
      "        [2.5583],\n",
      "        [2.4642],\n",
      "        [2.5000],\n",
      "        [2.5312],\n",
      "        [2.5623],\n",
      "        [2.5766],\n",
      "        [2.4665]], grad_fn=<GatherBackward>)\n",
      "tensor([[2.0960],\n",
      "        [2.2933],\n",
      "        [2.3272],\n",
      "        [2.2640],\n",
      "        [2.2405],\n",
      "        [1.9682],\n",
      "        [2.2565],\n",
      "        [2.3104],\n",
      "        [2.1175],\n",
      "        [2.2058],\n",
      "        [1.0000],\n",
      "        [2.1982],\n",
      "        [2.2892],\n",
      "        [2.2576],\n",
      "        [2.1895],\n",
      "        [2.2394],\n",
      "        [2.2348],\n",
      "        [2.0921],\n",
      "        [2.2513],\n",
      "        [2.1334],\n",
      "        [2.0617],\n",
      "        [2.0029],\n",
      "        [2.2608],\n",
      "        [2.1567],\n",
      "        [2.2741],\n",
      "        [2.3221],\n",
      "        [2.2449],\n",
      "        [1.0000],\n",
      "        [2.1957],\n",
      "        [2.3140],\n",
      "        [2.0888],\n",
      "        [2.2379],\n",
      "        [2.1644],\n",
      "        [1.9901],\n",
      "        [2.2802],\n",
      "        [1.9078],\n",
      "        [2.0953],\n",
      "        [2.3631],\n",
      "        [2.2994],\n",
      "        [2.2054],\n",
      "        [1.9768],\n",
      "        [2.0265],\n",
      "        [2.2902],\n",
      "        [1.9891],\n",
      "        [2.4134],\n",
      "        [1.0000],\n",
      "        [2.2448],\n",
      "        [2.0794],\n",
      "        [2.3026],\n",
      "        [2.2066],\n",
      "        [2.2261],\n",
      "        [2.2110],\n",
      "        [1.9912],\n",
      "        [2.3312],\n",
      "        [2.2946],\n",
      "        [2.3425],\n",
      "        [2.2685],\n",
      "        [2.2495],\n",
      "        [2.1847],\n",
      "        [2.3085],\n",
      "        [2.3827],\n",
      "        [1.9326],\n",
      "        [2.2297],\n",
      "        [2.2381],\n",
      "        [1.0000],\n",
      "        [1.8513],\n",
      "        [2.0387],\n",
      "        [2.0048],\n",
      "        [1.8882],\n",
      "        [2.3022],\n",
      "        [2.2723],\n",
      "        [2.2938],\n",
      "        [2.2893],\n",
      "        [2.1789],\n",
      "        [1.9452],\n",
      "        [2.3479],\n",
      "        [2.2696],\n",
      "        [1.8558],\n",
      "        [2.2398],\n",
      "        [2.0336],\n",
      "        [2.3463],\n",
      "        [2.2891],\n",
      "        [2.3168],\n",
      "        [2.1856],\n",
      "        [2.2363],\n",
      "        [2.2916],\n",
      "        [2.2229],\n",
      "        [2.2934],\n",
      "        [1.9607],\n",
      "        [2.2869],\n",
      "        [2.2620],\n",
      "        [2.2899],\n",
      "        [1.9476],\n",
      "        [2.2913],\n",
      "        [2.0285],\n",
      "        [2.3386],\n",
      "        [2.2348],\n",
      "        [2.2175],\n",
      "        [2.1929],\n",
      "        [2.1548],\n",
      "        [2.2835],\n",
      "        [1.0000],\n",
      "        [2.2129],\n",
      "        [2.1920],\n",
      "        [2.2164],\n",
      "        [2.1521],\n",
      "        [2.1765],\n",
      "        [1.8856],\n",
      "        [2.2066],\n",
      "        [2.4140],\n",
      "        [2.2710],\n",
      "        [2.2331],\n",
      "        [2.1197],\n",
      "        [1.0000],\n",
      "        [2.2012],\n",
      "        [2.2083],\n",
      "        [1.9803],\n",
      "        [2.1511],\n",
      "        [2.3367],\n",
      "        [1.0000],\n",
      "        [2.2941],\n",
      "        [2.2181],\n",
      "        [2.1493],\n",
      "        [2.0961],\n",
      "        [2.4226],\n",
      "        [2.2686],\n",
      "        [2.2395],\n",
      "        [2.1516]])\n",
      "============================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "torch.Size([128, 1])\n",
      "torch.Size([128, 1])\n",
      "tensor([[1.8829],\n",
      "        [1.6713],\n",
      "        [1.9560],\n",
      "        [1.8407],\n",
      "        [1.9718],\n",
      "        [1.8549],\n",
      "        [1.4922],\n",
      "        [1.9974],\n",
      "        [1.2125],\n",
      "        [2.0074],\n",
      "        [1.6425],\n",
      "        [1.9648],\n",
      "        [1.9201],\n",
      "        [1.8818],\n",
      "        [1.9657],\n",
      "        [1.7956],\n",
      "        [1.7215],\n",
      "        [1.5177],\n",
      "        [1.9928],\n",
      "        [1.8003],\n",
      "        [1.9079],\n",
      "        [1.9680],\n",
      "        [1.9526],\n",
      "        [1.9137],\n",
      "        [1.8596],\n",
      "        [1.8780],\n",
      "        [1.9193],\n",
      "        [1.9811],\n",
      "        [1.8495],\n",
      "        [1.9792],\n",
      "        [1.8954],\n",
      "        [1.8409],\n",
      "        [1.9308],\n",
      "        [1.7438],\n",
      "        [1.8313],\n",
      "        [1.4003],\n",
      "        [1.8669],\n",
      "        [1.8298],\n",
      "        [1.8158],\n",
      "        [1.8947],\n",
      "        [1.5601],\n",
      "        [0.7904],\n",
      "        [1.6706],\n",
      "        [0.4780],\n",
      "        [1.8874],\n",
      "        [1.9669],\n",
      "        [1.7217],\n",
      "        [0.6599],\n",
      "        [1.8619],\n",
      "        [1.8160],\n",
      "        [1.9573],\n",
      "        [1.5075],\n",
      "        [1.1217],\n",
      "        [1.5479],\n",
      "        [1.8893],\n",
      "        [1.9231],\n",
      "        [1.7349],\n",
      "        [1.4862],\n",
      "        [1.8387],\n",
      "        [1.9579],\n",
      "        [1.5369],\n",
      "        [1.8679],\n",
      "        [2.0203],\n",
      "        [1.9086],\n",
      "        [1.9866],\n",
      "        [1.9032],\n",
      "        [1.8226],\n",
      "        [1.9251],\n",
      "        [1.7819],\n",
      "        [1.9423],\n",
      "        [1.9146],\n",
      "        [1.9201],\n",
      "        [1.8829],\n",
      "        [1.9097],\n",
      "        [1.9449],\n",
      "        [1.9710],\n",
      "        [1.9866],\n",
      "        [1.4761],\n",
      "        [1.9669],\n",
      "        [1.9201],\n",
      "        [1.9201],\n",
      "        [1.8949],\n",
      "        [2.0064],\n",
      "        [1.9884],\n",
      "        [1.7692],\n",
      "        [1.4607],\n",
      "        [1.9390],\n",
      "        [1.4720],\n",
      "        [1.9777],\n",
      "        [1.9501],\n",
      "        [1.9201],\n",
      "        [1.5959],\n",
      "        [1.7125],\n",
      "        [1.9184],\n",
      "        [1.9621],\n",
      "        [1.9647],\n",
      "        [1.9712],\n",
      "        [1.8410],\n",
      "        [1.4799],\n",
      "        [1.9201],\n",
      "        [1.6454],\n",
      "        [1.9201],\n",
      "        [1.9201],\n",
      "        [1.6829],\n",
      "        [1.6725],\n",
      "        [1.7511],\n",
      "        [1.9107],\n",
      "        [1.8326],\n",
      "        [1.9142],\n",
      "        [1.8508],\n",
      "        [1.8555],\n",
      "        [1.6166],\n",
      "        [1.9079],\n",
      "        [1.6580],\n",
      "        [1.8702],\n",
      "        [1.8553],\n",
      "        [1.9122],\n",
      "        [1.9723],\n",
      "        [1.5350],\n",
      "        [0.6868],\n",
      "        [1.7267],\n",
      "        [1.8715],\n",
      "        [0.4377],\n",
      "        [1.6811],\n",
      "        [2.0155],\n",
      "        [0.7350],\n",
      "        [1.7854],\n",
      "        [1.9179]], grad_fn=<GatherBackward>)\n",
      "tensor([[2.2933],\n",
      "        [2.0119],\n",
      "        [2.2351],\n",
      "        [2.1521],\n",
      "        [2.2528],\n",
      "        [2.2129],\n",
      "        [1.9326],\n",
      "        [2.2444],\n",
      "        [1.9078],\n",
      "        [2.2941],\n",
      "        [2.2341],\n",
      "        [2.0705],\n",
      "        [2.2569],\n",
      "        [2.2709],\n",
      "        [2.3193],\n",
      "        [2.2606],\n",
      "        [1.9803],\n",
      "        [2.0126],\n",
      "        [2.2834],\n",
      "        [2.1334],\n",
      "        [2.1957],\n",
      "        [2.3631],\n",
      "        [2.3034],\n",
      "        [2.2105],\n",
      "        [2.2627],\n",
      "        [2.2409],\n",
      "        [2.2394],\n",
      "        [2.3085],\n",
      "        [2.0617],\n",
      "        [2.2678],\n",
      "        [2.2030],\n",
      "        [2.1159],\n",
      "        [2.2476],\n",
      "        [2.2741],\n",
      "        [2.1355],\n",
      "        [2.1175],\n",
      "        [2.1982],\n",
      "        [2.0265],\n",
      "        [1.9801],\n",
      "        [2.2710],\n",
      "        [1.9678],\n",
      "        [1.0000],\n",
      "        [1.9476],\n",
      "        [1.0000],\n",
      "        [2.2359],\n",
      "        [2.2634],\n",
      "        [2.2058],\n",
      "        [1.0000],\n",
      "        [2.2348],\n",
      "        [2.2012],\n",
      "        [2.3312],\n",
      "        [1.8856],\n",
      "        [2.0961],\n",
      "        [1.8309],\n",
      "        [2.2576],\n",
      "        [2.2066],\n",
      "        [2.1301],\n",
      "        [2.0278],\n",
      "        [1.9907],\n",
      "        [2.2891],\n",
      "        [1.8558],\n",
      "        [2.2398],\n",
      "        [2.2663],\n",
      "        [2.2946],\n",
      "        [2.2772],\n",
      "        [2.2994],\n",
      "        [2.0285],\n",
      "        [2.3600],\n",
      "        [2.1644],\n",
      "        [2.2472],\n",
      "        [2.2753],\n",
      "        [2.2945],\n",
      "        [2.2948],\n",
      "        [2.3272],\n",
      "        [2.0960],\n",
      "        [2.3767],\n",
      "        [2.3140],\n",
      "        [2.1072],\n",
      "        [2.3352],\n",
      "        [2.3022],\n",
      "        [2.2916],\n",
      "        [2.2328],\n",
      "        [2.2654],\n",
      "        [2.3425],\n",
      "        [1.7655],\n",
      "        [1.9912],\n",
      "        [2.2747],\n",
      "        [1.0000],\n",
      "        [2.3071],\n",
      "        [2.2449],\n",
      "        [2.2944],\n",
      "        [1.0000],\n",
      "        [1.9011],\n",
      "        [2.3215],\n",
      "        [2.1847],\n",
      "        [2.2405],\n",
      "        [2.3987],\n",
      "        [2.2910],\n",
      "        [2.2329],\n",
      "        [2.2937],\n",
      "        [1.0000],\n",
      "        [2.2399],\n",
      "        [2.2934],\n",
      "        [2.2175],\n",
      "        [1.9607],\n",
      "        [2.0953],\n",
      "        [2.1490],\n",
      "        [2.1765],\n",
      "        [2.2805],\n",
      "        [2.1511],\n",
      "        [2.2617],\n",
      "        [1.9358],\n",
      "        [2.2696],\n",
      "        [1.9642],\n",
      "        [2.2835],\n",
      "        [2.2181],\n",
      "        [2.1929],\n",
      "        [2.2817],\n",
      "        [2.1895],\n",
      "        [2.0230],\n",
      "        [1.8882],\n",
      "        [2.3026],\n",
      "        [1.0000],\n",
      "        [1.9866],\n",
      "        [2.2885],\n",
      "        [2.2065],\n",
      "        [2.2066],\n",
      "        [2.3077]])\n",
      "============================\n",
      "============================\n",
      "torch.Size([128, 1])\n",
      "torch.Size([128, 1])\n",
      "tensor([[2.4699],\n",
      "        [2.4914],\n",
      "        [2.1790],\n",
      "        [2.4210],\n",
      "        [2.4762],\n",
      "        [2.5738],\n",
      "        [2.2827],\n",
      "        [2.2543],\n",
      "        [2.4269],\n",
      "        [2.4699],\n",
      "        [2.3742],\n",
      "        [2.2525],\n",
      "        [2.4550],\n",
      "        [2.5075],\n",
      "        [2.2354],\n",
      "        [1.9766],\n",
      "        [2.3325],\n",
      "        [2.3262],\n",
      "        [2.4166],\n",
      "        [2.2655],\n",
      "        [2.3537],\n",
      "        [2.1441],\n",
      "        [2.3244],\n",
      "        [2.4439],\n",
      "        [2.4152],\n",
      "        [2.4180],\n",
      "        [2.3189],\n",
      "        [2.3539],\n",
      "        [1.6046],\n",
      "        [2.5470],\n",
      "        [2.3019],\n",
      "        [2.3355],\n",
      "        [2.5250],\n",
      "        [2.4699],\n",
      "        [2.4821],\n",
      "        [2.4699],\n",
      "        [2.2717],\n",
      "        [1.9269],\n",
      "        [2.4811],\n",
      "        [1.9450],\n",
      "        [2.4765],\n",
      "        [2.4104],\n",
      "        [2.4428],\n",
      "        [2.1249],\n",
      "        [1.8574],\n",
      "        [2.4165],\n",
      "        [2.4872],\n",
      "        [2.3208],\n",
      "        [2.4699],\n",
      "        [2.2593],\n",
      "        [2.5116],\n",
      "        [2.2621],\n",
      "        [2.4699],\n",
      "        [2.1559],\n",
      "        [2.4165],\n",
      "        [2.3176],\n",
      "        [2.0292],\n",
      "        [2.3458],\n",
      "        [2.2735],\n",
      "        [2.4459],\n",
      "        [2.3052],\n",
      "        [2.2985],\n",
      "        [2.4746],\n",
      "        [2.3258],\n",
      "        [2.1961],\n",
      "        [2.4699],\n",
      "        [2.3887],\n",
      "        [2.2629],\n",
      "        [2.3750],\n",
      "        [2.1842],\n",
      "        [2.4699],\n",
      "        [2.4241],\n",
      "        [1.8286],\n",
      "        [2.3590],\n",
      "        [2.2464],\n",
      "        [2.3417],\n",
      "        [2.4989],\n",
      "        [2.4190],\n",
      "        [2.3493],\n",
      "        [2.2830],\n",
      "        [2.4640],\n",
      "        [2.3403],\n",
      "        [2.1889],\n",
      "        [2.2917],\n",
      "        [2.3208],\n",
      "        [2.3385],\n",
      "        [2.2566],\n",
      "        [2.4180],\n",
      "        [2.2867],\n",
      "        [1.9512],\n",
      "        [2.3807],\n",
      "        [2.2352],\n",
      "        [2.2569],\n",
      "        [2.2896],\n",
      "        [2.1399],\n",
      "        [2.2393],\n",
      "        [2.0486],\n",
      "        [2.3993],\n",
      "        [2.4514],\n",
      "        [2.3524],\n",
      "        [2.4427],\n",
      "        [2.4166],\n",
      "        [2.4473],\n",
      "        [2.2499],\n",
      "        [2.4624],\n",
      "        [1.9275],\n",
      "        [2.3260],\n",
      "        [2.4699],\n",
      "        [2.3846],\n",
      "        [2.5004],\n",
      "        [1.9950],\n",
      "        [2.4823],\n",
      "        [2.1383],\n",
      "        [2.2598],\n",
      "        [1.8265],\n",
      "        [2.2584],\n",
      "        [2.5356],\n",
      "        [2.3306],\n",
      "        [1.8924],\n",
      "        [2.0459],\n",
      "        [2.2394],\n",
      "        [2.4176],\n",
      "        [2.2681],\n",
      "        [2.3810],\n",
      "        [2.3559],\n",
      "        [2.1504],\n",
      "        [2.4699],\n",
      "        [2.4658]], grad_fn=<GatherBackward>)\n",
      "tensor([[2.2937],\n",
      "        [2.2747],\n",
      "        [1.8954],\n",
      "        [2.2869],\n",
      "        [2.3827],\n",
      "        [2.2110],\n",
      "        [2.2950],\n",
      "        [2.0387],\n",
      "        [2.4813],\n",
      "        [2.2916],\n",
      "        [2.2472],\n",
      "        [2.1159],\n",
      "        [2.1548],\n",
      "        [2.2329],\n",
      "        [2.0745],\n",
      "        [2.0230],\n",
      "        [2.2772],\n",
      "        [2.2341],\n",
      "        [2.3352],\n",
      "        [2.2427],\n",
      "        [2.1192],\n",
      "        [1.9768],\n",
      "        [2.2443],\n",
      "        [2.2834],\n",
      "        [2.3589],\n",
      "        [2.2058],\n",
      "        [2.1355],\n",
      "        [2.2606],\n",
      "        [2.0048],\n",
      "        [2.2341],\n",
      "        [2.1511],\n",
      "        [2.0533],\n",
      "        [2.3071],\n",
      "        [2.3022],\n",
      "        [2.2175],\n",
      "        [2.2893],\n",
      "        [2.2516],\n",
      "        [1.0000],\n",
      "        [2.2994],\n",
      "        [1.9891],\n",
      "        [2.1567],\n",
      "        [2.2723],\n",
      "        [2.2066],\n",
      "        [1.8558],\n",
      "        [1.0000],\n",
      "        [2.1789],\n",
      "        [2.3137],\n",
      "        [2.0490],\n",
      "        [2.2569],\n",
      "        [2.1653],\n",
      "        [2.3479],\n",
      "        [2.1521],\n",
      "        [2.2913],\n",
      "        [1.9689],\n",
      "        [2.2381],\n",
      "        [2.3215],\n",
      "        [1.8513],\n",
      "        [2.2237],\n",
      "        [2.2382],\n",
      "        [2.2696],\n",
      "        [2.2229],\n",
      "        [2.1856],\n",
      "        [2.3463],\n",
      "        [2.2910],\n",
      "        [1.7655],\n",
      "        [2.2399],\n",
      "        [2.2909],\n",
      "        [2.0265],\n",
      "        [2.1666],\n",
      "        [1.9803],\n",
      "        [2.2640],\n",
      "        [2.2620],\n",
      "        [2.1175],\n",
      "        [2.0617],\n",
      "        [2.4134],\n",
      "        [2.0594],\n",
      "        [2.1301],\n",
      "        [2.2448],\n",
      "        [2.2892],\n",
      "        [2.2565],\n",
      "        [2.2379],\n",
      "        [2.3221],\n",
      "        [2.0356],\n",
      "        [2.1982],\n",
      "        [2.2066],\n",
      "        [2.2495],\n",
      "        [2.1543],\n",
      "        [2.3085],\n",
      "        [2.2054],\n",
      "        [1.0000],\n",
      "        [2.1499],\n",
      "        [1.8309],\n",
      "        [2.0029],\n",
      "        [2.2359],\n",
      "        [1.9497],\n",
      "        [2.2751],\n",
      "        [1.8263],\n",
      "        [2.2351],\n",
      "        [2.2508],\n",
      "        [2.2624],\n",
      "        [2.0291],\n",
      "        [2.2685],\n",
      "        [2.3367],\n",
      "        [2.2348],\n",
      "        [2.2654],\n",
      "        [2.0278],\n",
      "        [2.2899],\n",
      "        [2.2910],\n",
      "        [2.2409],\n",
      "        [2.0921],\n",
      "        [1.9437],\n",
      "        [2.2781],\n",
      "        [1.9737],\n",
      "        [1.9894],\n",
      "        [1.0000],\n",
      "        [2.2768],\n",
      "        [2.3017],\n",
      "        [2.2977],\n",
      "        [2.1423],\n",
      "        [1.0000],\n",
      "        [2.2363],\n",
      "        [2.2918],\n",
      "        [2.2606],\n",
      "        [2.2948],\n",
      "        [2.2891],\n",
      "        [1.9476],\n",
      "        [2.2405],\n",
      "        [2.2620]])\n",
      "============================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "torch.Size([128, 1])\n",
      "torch.Size([128, 1])\n",
      "tensor([[2.0748],\n",
      "        [2.0982],\n",
      "        [1.7513],\n",
      "        [2.1120],\n",
      "        [2.0695],\n",
      "        [1.9301],\n",
      "        [0.9929],\n",
      "        [1.9950],\n",
      "        [2.0282],\n",
      "        [2.1464],\n",
      "        [2.0652],\n",
      "        [1.2566],\n",
      "        [1.9679],\n",
      "        [2.0103],\n",
      "        [2.1064],\n",
      "        [2.0444],\n",
      "        [1.6170],\n",
      "        [1.8670],\n",
      "        [2.0495],\n",
      "        [1.7447],\n",
      "        [1.9543],\n",
      "        [2.1058],\n",
      "        [2.1129],\n",
      "        [1.8567],\n",
      "        [2.0860],\n",
      "        [2.0404],\n",
      "        [1.6243],\n",
      "        [1.8797],\n",
      "        [2.0518],\n",
      "        [2.0348],\n",
      "        [2.1316],\n",
      "        [2.1455],\n",
      "        [1.8361],\n",
      "        [2.0924],\n",
      "        [1.8572],\n",
      "        [1.9636],\n",
      "        [1.6416],\n",
      "        [2.1584],\n",
      "        [2.0594],\n",
      "        [1.9787],\n",
      "        [2.0874],\n",
      "        [2.0924],\n",
      "        [2.0973],\n",
      "        [2.0490],\n",
      "        [2.1767],\n",
      "        [1.7834],\n",
      "        [1.9954],\n",
      "        [1.6045],\n",
      "        [2.1610],\n",
      "        [2.0890],\n",
      "        [2.1365],\n",
      "        [1.3107],\n",
      "        [2.0932],\n",
      "        [1.9703],\n",
      "        [1.9927],\n",
      "        [2.0924],\n",
      "        [2.0924],\n",
      "        [2.1343],\n",
      "        [2.0368],\n",
      "        [1.9963],\n",
      "        [2.0715],\n",
      "        [2.0995],\n",
      "        [2.0005],\n",
      "        [2.0882],\n",
      "        [2.1368],\n",
      "        [1.8712],\n",
      "        [1.8740],\n",
      "        [2.0300],\n",
      "        [1.9429],\n",
      "        [2.1626],\n",
      "        [1.9896],\n",
      "        [2.0742],\n",
      "        [1.2522],\n",
      "        [2.1771],\n",
      "        [1.8294],\n",
      "        [1.9508],\n",
      "        [2.1094],\n",
      "        [2.0708],\n",
      "        [2.0250],\n",
      "        [1.9931],\n",
      "        [2.0148],\n",
      "        [2.0776],\n",
      "        [2.0093],\n",
      "        [2.0336],\n",
      "        [1.9752],\n",
      "        [2.1020],\n",
      "        [2.0576],\n",
      "        [1.9722],\n",
      "        [1.9489],\n",
      "        [1.6898],\n",
      "        [2.1131],\n",
      "        [2.0469],\n",
      "        [2.1517],\n",
      "        [1.8322],\n",
      "        [1.8064],\n",
      "        [2.1184],\n",
      "        [1.8364],\n",
      "        [2.0350],\n",
      "        [2.0046],\n",
      "        [2.0017],\n",
      "        [2.0362],\n",
      "        [2.0895],\n",
      "        [2.1115],\n",
      "        [2.0060],\n",
      "        [2.0055],\n",
      "        [2.0490],\n",
      "        [2.0953],\n",
      "        [1.8383],\n",
      "        [2.0924],\n",
      "        [1.7391],\n",
      "        [2.0921],\n",
      "        [2.1155],\n",
      "        [2.0763],\n",
      "        [2.1024],\n",
      "        [1.4134],\n",
      "        [2.0924],\n",
      "        [2.0494],\n",
      "        [2.1087],\n",
      "        [1.8826],\n",
      "        [2.0924],\n",
      "        [2.1594],\n",
      "        [1.9711],\n",
      "        [2.1791],\n",
      "        [2.1595],\n",
      "        [1.8668],\n",
      "        [2.0320],\n",
      "        [2.0057],\n",
      "        [1.7032]], grad_fn=<GatherBackward>)\n",
      "tensor([[2.2624],\n",
      "        [2.2351],\n",
      "        [1.9682],\n",
      "        [2.2331],\n",
      "        [2.2495],\n",
      "        [2.0119],\n",
      "        [1.0000],\n",
      "        [2.2751],\n",
      "        [2.1493],\n",
      "        [2.2444],\n",
      "        [2.2899],\n",
      "        [1.0000],\n",
      "        [2.1201],\n",
      "        [2.1644],\n",
      "        [2.2634],\n",
      "        [2.2398],\n",
      "        [2.2950],\n",
      "        [1.9791],\n",
      "        [2.2237],\n",
      "        [1.9678],\n",
      "        [2.0285],\n",
      "        [2.2395],\n",
      "        [2.2508],\n",
      "        [1.9803],\n",
      "        [2.3386],\n",
      "        [2.2129],\n",
      "        [1.9912],\n",
      "        [1.9011],\n",
      "        [2.2772],\n",
      "        [2.2297],\n",
      "        [2.3479],\n",
      "        [2.3193],\n",
      "        [1.9497],\n",
      "        [2.2944],\n",
      "        [1.9576],\n",
      "        [1.9907],\n",
      "        [1.0000],\n",
      "        [2.3071],\n",
      "        [2.2835],\n",
      "        [2.1765],\n",
      "        [2.3034],\n",
      "        [2.2640],\n",
      "        [2.3827],\n",
      "        [2.2627],\n",
      "        [2.3794],\n",
      "        [1.9326],\n",
      "        [2.2427],\n",
      "        [2.1423],\n",
      "        [2.3425],\n",
      "        [2.2686],\n",
      "        [2.1847],\n",
      "        [1.0000],\n",
      "        [2.3272],\n",
      "        [2.4134],\n",
      "        [2.2606],\n",
      "        [2.2910],\n",
      "        [2.2937],\n",
      "        [2.2918],\n",
      "        [2.1936],\n",
      "        [2.1511],\n",
      "        [2.2977],\n",
      "        [2.3312],\n",
      "        [2.2768],\n",
      "        [2.3635],\n",
      "        [2.1672],\n",
      "        [1.9642],\n",
      "        [1.9901],\n",
      "        [2.2110],\n",
      "        [2.1072],\n",
      "        [2.2885],\n",
      "        [2.2083],\n",
      "        [2.0960],\n",
      "        [2.0291],\n",
      "        [2.3140],\n",
      "        [2.0199],\n",
      "        [2.2565],\n",
      "        [2.2448],\n",
      "        [2.1301],\n",
      "        [2.2348],\n",
      "        [2.0794],\n",
      "        [2.2175],\n",
      "        [2.2576],\n",
      "        [2.1653],\n",
      "        [2.0921],\n",
      "        [2.1159],\n",
      "        [2.2902],\n",
      "        [2.2066],\n",
      "        [2.2993],\n",
      "        [1.9358],\n",
      "        [1.8513],\n",
      "        [2.2620],\n",
      "        [2.2753],\n",
      "        [2.2941],\n",
      "        [1.9768],\n",
      "        [1.9476],\n",
      "        [2.2678],\n",
      "        [1.9678],\n",
      "        [2.2710],\n",
      "        [2.2516],\n",
      "        [2.1856],\n",
      "        [2.0490],\n",
      "        [2.1957],\n",
      "        [2.2476],\n",
      "        [2.2910],\n",
      "        [2.1355],\n",
      "        [2.3215],\n",
      "        [2.2948],\n",
      "        [2.0336],\n",
      "        [2.2569],\n",
      "        [1.9078],\n",
      "        [2.2696],\n",
      "        [2.4140],\n",
      "        [2.2164],\n",
      "        [2.2909],\n",
      "        [1.0000],\n",
      "        [2.2913],\n",
      "        [2.2617],\n",
      "        [2.3631],\n",
      "        [2.0533],\n",
      "        [2.3022],\n",
      "        [2.2802],\n",
      "        [2.1521],\n",
      "        [2.3017],\n",
      "        [2.2663],\n",
      "        [2.0387],\n",
      "        [2.2066],\n",
      "        [2.1516],\n",
      "        [2.0126]])\n",
      "============================\n",
      "============================\n",
      "torch.Size([128, 1])\n",
      "torch.Size([128, 1])\n",
      "tensor([[2.4658],\n",
      "        [2.5045],\n",
      "        [2.3969],\n",
      "        [2.4939],\n",
      "        [2.2813],\n",
      "        [2.2666],\n",
      "        [2.3302],\n",
      "        [2.3989],\n",
      "        [2.4850],\n",
      "        [2.3942],\n",
      "        [2.4261],\n",
      "        [2.4920],\n",
      "        [2.4841],\n",
      "        [2.3133],\n",
      "        [2.4835],\n",
      "        [2.4140],\n",
      "        [2.3831],\n",
      "        [2.3598],\n",
      "        [2.4122],\n",
      "        [2.4337],\n",
      "        [2.3889],\n",
      "        [2.3895],\n",
      "        [2.3081],\n",
      "        [2.3502],\n",
      "        [2.3719],\n",
      "        [2.4800],\n",
      "        [2.3509],\n",
      "        [1.6644],\n",
      "        [2.4959],\n",
      "        [2.2064],\n",
      "        [2.4616],\n",
      "        [2.4708],\n",
      "        [2.3799],\n",
      "        [2.4241],\n",
      "        [2.3427],\n",
      "        [2.3738],\n",
      "        [2.4183],\n",
      "        [1.2948],\n",
      "        [2.3445],\n",
      "        [2.3938],\n",
      "        [2.3204],\n",
      "        [2.3543],\n",
      "        [2.3102],\n",
      "        [2.4295],\n",
      "        [2.2804],\n",
      "        [2.3924],\n",
      "        [1.3936],\n",
      "        [2.4313],\n",
      "        [2.0364],\n",
      "        [2.3424],\n",
      "        [2.4759],\n",
      "        [2.4055],\n",
      "        [2.3750],\n",
      "        [2.3414],\n",
      "        [2.4826],\n",
      "        [2.4172],\n",
      "        [1.9151],\n",
      "        [1.9835],\n",
      "        [2.3090],\n",
      "        [2.2967],\n",
      "        [2.4861],\n",
      "        [2.4178],\n",
      "        [2.5087],\n",
      "        [2.3505],\n",
      "        [2.3333],\n",
      "        [2.1323],\n",
      "        [2.4194],\n",
      "        [2.3418],\n",
      "        [1.2796],\n",
      "        [2.3181],\n",
      "        [2.4067],\n",
      "        [2.3004],\n",
      "        [2.4210],\n",
      "        [2.1074],\n",
      "        [2.3312],\n",
      "        [2.4582],\n",
      "        [2.4946],\n",
      "        [2.2944],\n",
      "        [2.2635],\n",
      "        [2.1879],\n",
      "        [2.4267],\n",
      "        [2.4378],\n",
      "        [2.4652],\n",
      "        [2.3300],\n",
      "        [2.3891],\n",
      "        [2.5207],\n",
      "        [2.4844],\n",
      "        [2.2742],\n",
      "        [2.0283],\n",
      "        [2.4800],\n",
      "        [2.2877],\n",
      "        [2.0397],\n",
      "        [2.4309],\n",
      "        [1.8331],\n",
      "        [2.4859],\n",
      "        [2.3743],\n",
      "        [2.1117],\n",
      "        [2.3527],\n",
      "        [2.4777],\n",
      "        [2.1496],\n",
      "        [2.2169],\n",
      "        [2.5250],\n",
      "        [2.0468],\n",
      "        [2.3753],\n",
      "        [2.3785],\n",
      "        [1.8941],\n",
      "        [2.3235],\n",
      "        [1.3391],\n",
      "        [2.4313],\n",
      "        [2.4367],\n",
      "        [2.3061],\n",
      "        [2.4313],\n",
      "        [2.1446],\n",
      "        [2.3017],\n",
      "        [2.4141],\n",
      "        [2.3428],\n",
      "        [2.2096],\n",
      "        [1.3936],\n",
      "        [2.3359],\n",
      "        [2.4814],\n",
      "        [2.3451],\n",
      "        [1.9190],\n",
      "        [1.4845],\n",
      "        [2.4313],\n",
      "        [2.3558],\n",
      "        [2.4270],\n",
      "        [2.3558],\n",
      "        [1.8198]], grad_fn=<GatherBackward>)\n",
      "tensor([[2.2938],\n",
      "        [2.3017],\n",
      "        [2.2012],\n",
      "        [2.2737],\n",
      "        [2.0794],\n",
      "        [2.0859],\n",
      "        [2.2606],\n",
      "        [2.1334],\n",
      "        [2.3085],\n",
      "        [2.2386],\n",
      "        [2.2620],\n",
      "        [2.2678],\n",
      "        [2.2817],\n",
      "        [2.0265],\n",
      "        [2.2528],\n",
      "        [2.2696],\n",
      "        [2.2066],\n",
      "        [2.1490],\n",
      "        [2.2237],\n",
      "        [2.2686],\n",
      "        [2.2899],\n",
      "        [2.3026],\n",
      "        [2.0387],\n",
      "        [2.1511],\n",
      "        [2.2753],\n",
      "        [2.3193],\n",
      "        [2.2030],\n",
      "        [1.0000],\n",
      "        [2.2772],\n",
      "        [1.8882],\n",
      "        [2.2110],\n",
      "        [2.2164],\n",
      "        [2.2394],\n",
      "        [2.2805],\n",
      "        [2.1201],\n",
      "        [2.4813],\n",
      "        [2.2891],\n",
      "        [1.0000],\n",
      "        [2.2359],\n",
      "        [2.2977],\n",
      "        [2.2768],\n",
      "        [2.2608],\n",
      "        [2.2348],\n",
      "        [2.2379],\n",
      "        [2.2606],\n",
      "        [2.2476],\n",
      "        [1.0000],\n",
      "        [2.2934],\n",
      "        [1.9689],\n",
      "        [2.3104],\n",
      "        [2.2405],\n",
      "        [2.0533],\n",
      "        [2.1301],\n",
      "        [2.1895],\n",
      "        [2.3767],\n",
      "        [2.3272],\n",
      "        [1.0000],\n",
      "        [2.0126],\n",
      "        [2.1936],\n",
      "        [1.9907],\n",
      "        [2.2620],\n",
      "        [2.2892],\n",
      "        [2.2834],\n",
      "        [2.2054],\n",
      "        [2.2516],\n",
      "        [1.9497],\n",
      "        [2.2261],\n",
      "        [2.2948],\n",
      "        [1.0000],\n",
      "        [2.2353],\n",
      "        [2.2508],\n",
      "        [2.2363],\n",
      "        [2.3386],\n",
      "        [1.9576],\n",
      "        [2.2627],\n",
      "        [2.3312],\n",
      "        [2.3987],\n",
      "        [2.0745],\n",
      "        [1.9607],\n",
      "        [2.0330],\n",
      "        [2.3034],\n",
      "        [2.1666],\n",
      "        [2.2395],\n",
      "        [2.2083],\n",
      "        [2.2576],\n",
      "        [2.3425],\n",
      "        [2.3377],\n",
      "        [1.9011],\n",
      "        [1.8856],\n",
      "        [2.1672],\n",
      "        [2.0953],\n",
      "        [2.1197],\n",
      "        [2.0743],\n",
      "        [2.1423],\n",
      "        [2.2621],\n",
      "        [2.4226],\n",
      "        [1.9452],\n",
      "        [2.2710],\n",
      "        [2.2685],\n",
      "        [1.9866],\n",
      "        [2.2993],\n",
      "        [2.2513],\n",
      "        [1.9768],\n",
      "        [2.0490],\n",
      "        [2.3215],\n",
      "        [1.0000],\n",
      "        [2.1653],\n",
      "        [1.0000],\n",
      "        [2.2944],\n",
      "        [2.3827],\n",
      "        [2.4134],\n",
      "        [2.2937],\n",
      "        [1.9737],\n",
      "        [2.0029],\n",
      "        [2.1192],\n",
      "        [2.2835],\n",
      "        [1.9078],\n",
      "        [2.0048],\n",
      "        [2.2409],\n",
      "        [2.1789],\n",
      "        [2.1982],\n",
      "        [1.8263],\n",
      "        [2.2065],\n",
      "        [2.2640],\n",
      "        [2.1355],\n",
      "        [2.2604],\n",
      "        [2.1493],\n",
      "        [1.9891]])\n",
      "============================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-7ff4e0ef9fbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# Perform one step of the optimization (on the target network)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0moptimize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-fa6093b68256>\u001b[0m in \u001b[0;36moptimize_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# columns of actions taken. These are the actions which would've been taken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# for each batch state according to policy_net\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mstate_action_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# Compute V(s_{t+1}) for all next states.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-88ab1d3c0af0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 342\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_episodes = 50\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and state\n",
    "    env.reset()\n",
    "    last_screen = get_screen()\n",
    "    current_screen = get_screen()\n",
    "    state = current_screen - last_screen\n",
    "    \n",
    "    for t in count():\n",
    "        # Select and perform an action\n",
    "        action = select_action(state)\n",
    "        _, reward, done, _ = env.step(action.item())\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "\n",
    "        # Observe new state\n",
    "        last_screen = current_screen\n",
    "        current_screen = get_screen()\n",
    "        if not done:\n",
    "            next_state = current_screen - last_screen\n",
    "        else:\n",
    "            next_state = None\n",
    "\n",
    "        # Store the transition in memory\n",
    "        memory.push(state, action, next_state, reward)\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the target network)\n",
    "        optimize_model()\n",
    "        \n",
    "        if done:\n",
    "            episode_durations.append(t + 1)\n",
    "            plot_durations()\n",
    "            break\n",
    "    # Update the target network, copying all weights and biases in DQN\n",
    "    if i_episode % TARGET_UPDATE == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "    \n",
    "\n",
    "print('Complete')\n",
    "# env.render()\n",
    "# env.close()\n",
    "# plt.ioff()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the diagram that illustrates the overall resulting data flow.\n",
    "\n",
    ".. figure:: /_static/img/reinforcement_learning_diagram.jpg\n",
    "\n",
    "Actions are chosen either randomly or based on a policy, getting the next\n",
    "step sample from the gym environment. We record the results in the\n",
    "replay memory and also run optimization step on every iteration.\n",
    "Optimization picks a random batch from the replay memory to do training of the\n",
    "new policy. \"Older\" target_net is also used in optimization to compute the\n",
    "expected Q values; it is updated occasionally to keep it current.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
